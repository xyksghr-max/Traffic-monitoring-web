# Prometheus LLM ç›‘æ§ - å¿«é€Ÿå‚è€ƒ

## ğŸ¯ é—®é¢˜ï¼šhistogram_quantile æ²¡æœ‰æ•°æ®

### âœ… å·²ä¿®å¤
- âœ… `DangerousDrivingAnalyzer` ç°åœ¨è®°å½•æ‰€æœ‰ LLM è¯·æ±‚åˆ° Prometheus
- âœ… æˆåŠŸ/å¤±è´¥/é‡è¯• çŠ¶æ€éƒ½ä¼šè¢«è¿½è¸ª
- âœ… Token ä½¿ç”¨é‡è‡ªåŠ¨æå–
- âœ… å»¶è¿Ÿæ•°æ®è®°å½•åˆ° histogram buckets

---

## ğŸ“Š å¿«é€ŸéªŒè¯

### 1. æ£€æŸ¥ Flask Metrics
```powershell
curl http://localhost:5000/metrics | Select-String "llm_"
```

**é¢„æœŸè¾“å‡º**ï¼ˆå¦‚æœæœ‰ LLM è°ƒç”¨ï¼‰:
```
llm_latency_seconds_bucket{api_key_id="default",le="0.5",model="qwen-vl-plus"} 0.0
llm_latency_seconds_count{api_key_id="default",model="qwen-vl-plus"} 5.0
llm_requests_total{api_key_id="default",model="qwen-vl-plus",status="success"} 5.0
```

### 2. Prometheus æŸ¥è¯¢
è®¿é—® http://localhost:9100/graph

```promql
# æŸ¥çœ‹åŸå§‹æ•°æ®
llm_requests_total

# P95 å»¶è¿Ÿ
histogram_quantile(0.95, rate(llm_latency_seconds_bucket[5m]))

# å¹³å‡å»¶è¿Ÿ
rate(llm_latency_seconds_sum[5m]) / rate(llm_latency_seconds_count[5m])

# æˆåŠŸç‡
sum(rate(llm_requests_total{status="success"}[5m])) / sum(rate(llm_requests_total[5m])) * 100
```

---

## âš ï¸ é‡è¦ï¼šéœ€è¦è§¦å‘ LLM è°ƒç”¨

**æŒ‡æ ‡åªåœ¨å®é™… LLM è°ƒç”¨æ—¶æ‰ä¼šäº§ç”Ÿï¼**

### è§¦å‘æ¡ä»¶ï¼ˆå…¨éƒ¨æ»¡è¶³ï¼‰ï¼š
1. âœ… æ‘„åƒå¤´æµæ­£åœ¨è¿è¡Œ
2. âœ… æ£€æµ‹åˆ° â‰¥2 ä¸ªå¯¹è±¡ æˆ– å½¢æˆäº¤é€šç»„
3. âœ… æ»¡è¶³ cooldown é—´éš”ï¼ˆé»˜è®¤ 3 ç§’ï¼‰
4. âœ… `model_config.yaml` ä¸­ `llm.enabled: true`
5. âœ… `DASHSCOPE_API_KEY` ç¯å¢ƒå˜é‡å·²è®¾ç½®

### å¿«é€Ÿæµ‹è¯•æ–¹æ³•ï¼š

**å¯åŠ¨æ‘„åƒå¤´**:
```powershell
# 1. å¯åŠ¨åº”ç”¨
python app.py

# 2. æ‰“å¼€æµè§ˆå™¨
# http://localhost:5000

# 3. æ·»åŠ æ‘„åƒå¤´å¹¶å¼€å§‹æ£€æµ‹
# - è¾“å…¥ RTSP URL æˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„
# - ç‚¹å‡»"å¼€å§‹æ£€æµ‹"
# - ç¡®ä¿è§†é¢‘ä¸­æœ‰å¤šä¸ªè½¦è¾†/è¡Œäºº

# 4. ç­‰å¾…å‡ åˆ†é’Ÿï¼Œè®© LLM åˆ†æè¿è¡Œå¤šæ¬¡
```

**æ£€æŸ¥æ—¥å¿—**ï¼ˆç¡®è®¤ LLM è¢«è°ƒç”¨ï¼‰:
```
INFO: DashScope API call successful, latency=2.34s
```

---

## ğŸ› å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ•°æ®

### æ£€æŸ¥æ¸…å•ï¼š

```powershell
# 1. Prometheus æ˜¯å¦æ­£å¸¸æŠ“å–ï¼Ÿ
curl http://localhost:9100/api/v1/targets | ConvertFrom-Json

# 2. Flask metrics ç«¯ç‚¹æ˜¯å¦å¯è®¿é—®ï¼Ÿ
curl http://localhost:5000/metrics

# 3. æ˜¯å¦æœ‰ä»»ä½• LLM è¯·æ±‚ï¼Ÿ
curl http://localhost:5000/metrics | Select-String "llm_requests_total"

# 4. æ£€æŸ¥ Flask æ—¥å¿—ï¼ˆæŸ¥æ‰¾ LLM è°ƒç”¨ï¼‰
# æœç´¢: "DashScope" æˆ– "analyze"
```

### å¸¸è§é—®é¢˜ï¼š

| ç—‡çŠ¶ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| `llm_requests_total` = 0 | æ²¡æœ‰ LLM è°ƒç”¨ | å¯åŠ¨æ‘„åƒå¤´æµï¼Œç¡®ä¿æ£€æµ‹åˆ°å¯¹è±¡ |
| Metrics ç«¯ç‚¹æ—  `llm_` | ä»£ç æœªæ‰§è¡Œ | é‡å¯ Flask åº”ç”¨ |
| Prometheus æ˜¾ç¤º 404 | Target é…ç½®é”™è¯¯ | æ£€æŸ¥ `prometheus.yml` |
| Bucket æ•°æ®ä¸ºç©º | æ—¶é—´èŒƒå›´å¤ªçŸ­ | ä½¿ç”¨ `[1h]` è€Œä¸æ˜¯ `[5m]` |

---

## ğŸ“ˆ æ¨è Grafana é¢æ¿

### Panel 1: LLM P95 å»¶è¿Ÿ
```promql
histogram_quantile(0.95, sum(rate(llm_latency_seconds_bucket[5m])) by (le, model))
```

### Panel 2: LLM è¯·æ±‚é€Ÿç‡
```promql
sum(rate(llm_requests_total[1m])) by (status)
```

### Panel 3: LLM æˆåŠŸç‡
```promql
sum(rate(llm_requests_total{status="success"}[5m])) 
/ 
sum(rate(llm_requests_total[5m])) * 100
```

### Panel 4: Token ä½¿ç”¨é‡
```promql
sum(rate(llm_token_usage_total[5m])) by (token_type)
```

---

## ğŸ“ ç›¸å…³æ–‡ä»¶

- **ä¿®å¤æ–‡ä»¶**: `algo/llm/dangerous_driving_detector.py`
- **æŒ‡æ ‡å®šä¹‰**: `algo/monitoring/metrics.py`
- **è¯¦ç»†æ–‡æ¡£**: `PROMETHEUS_NO_DATA_FIX.md`
- **Metrics ç«¯ç‚¹**: `app.py` (å·²é›†æˆ)

---

## ğŸ‰ ç°åœ¨å¯ä»¥ï¼š

âœ… è¿½è¸ª LLM API å»¶è¿Ÿï¼ˆP50/P95/P99ï¼‰  
âœ… ç›‘æ§ LLM è¯·æ±‚æˆåŠŸç‡  
âœ… ç»Ÿè®¡ Token ä½¿ç”¨é‡  
âœ… åˆ†æ LLM æ€§èƒ½ç“¶é¢ˆ  
âœ… è®¾ç½®å»¶è¿Ÿå‘Šè­¦ï¼ˆGrafana Alertsï¼‰

**é‡å¯åº”ç”¨åç«‹å³ç”Ÿæ•ˆï¼** ğŸš€
