# 🚀 实时危险画面检测系统并发优化 - 项目总结

## 📌 项目概述

本项目旨在通过引入 **Kafka消息队列**、**Flink流处理引擎** 和 **多API Key池化调度** 技术，将现有的实时危险画面检测系统的并发处理能力提升 **10倍以上**，支持 **50+路摄像头** 同时处理，并将端到端延迟降低到 **2秒以内**。

---

## 📁 已交付文档和代码

### 📖 设计文档

| 文档 | 路径 | 说明 |
|------|------|------|
| **架构优化实施方案** | `docs/架构优化实施方案.md` | 详细的技术方案，包含架构设计、模块划分、代码示例 |
| **快速开始指南** | `docs/快速开始指南.md` | 系统部署和配置的快速入门指南 |

### ⚙️ 配置文件

| 配置文件 | 路径 | 说明 |
|---------|------|------|
| **API Keys 配置** | `config/api_keys.yaml` | 多个 API Key 的配置和调度策略 |
| **Kafka 配置** | `config/kafka.yaml` | Kafka 集群、Topic、Producer/Consumer 配置 |
| **监控配置** | `config/monitoring.yaml` | Prometheus、Grafana、告警规则配置 |

### 🐳 部署文件

| 部署文件 | 路径 | 说明 |
|---------|------|------|
| **基础设施编排** | `deployment/docker-compose.infra.yml` | Kafka、Redis、Prometheus、Grafana 一键部署 |
| **Prometheus 配置** | `deployment/prometheus.yml` | Prometheus 采集目标配置 |
| **Grafana 数据源** | `deployment/grafana-datasources.yml` | Grafana 数据源自动配置 |

### 🛠️ 工具脚本

| 脚本 | 路径 | 说明 |
|------|------|------|
| **初始化 Kafka Topics** | `scripts/init_kafka_topics.py` | 自动创建所需的 Kafka Topics |
| **验证 API Keys** | `scripts/verify_api_keys.py` | 批量测试 API Key 可用性 |

### 📦 依赖包

| 文件 | 路径 | 说明 |
|------|------|------|
| **流处理依赖** | `requirements-streaming.txt` | Kafka、Redis、aiohttp 等新增依赖 |

---

## 🏗️ 核心架构设计

### 整体架构图

```
┌──────────────┐     ┌───────────────┐     ┌──────────────┐
│ 摄像头视频流  │────▶│ YOLO+BX聚类   │────▶│ Kafka        │
│ (N路并发)    │     │ 检测服务      │     │ Producer     │
└──────────────┘     └───────────────┘     └──────┬───────┘
                                                   │
                                                   ▼
                                         ┌──────────────────┐
                                         │ Kafka Cluster    │
                                         │ detection-results│
                                         └────────┬─────────┘
                                                  │
                                                  ▼
                                    ┌─────────────────────────┐
                                    │ Flink / Python          │
                                    │ 任务生成器               │
                                    │ - 数据验证               │
                                    │ - 格式转换               │
                                    │ - 任务分发               │
                                    └──────────┬──────────────┘
                                               │
                                               ▼
                                    ┌─────────────────────────┐
                                    │ LLM 任务调度器           │
                                    │ ┌─────────────────────┐ │
                                    │ │ API Key Pool        │ │
                                    │ │ - 多Key并发调用     │ │
                                    │ │ - 负载均衡          │ │
                                    │ │ - 失败重试          │ │
                                    │ │ - 自适应冷却        │ │
                                    │ └─────────────────────┘ │
                                    └──────────┬──────────────┘
                                               │
                                               ▼
                                    ┌─────────────────────────┐
                                    │ 多模态大模型 API         │
                                    │ (并发: N * QPS)         │
                                    └──────────┬──────────────┘
                                               │
                                               ▼
                                    ┌─────────────────────────┐
                                    │ Kafka                   │
                                    │ risk-assessment-results │
                                    └──────────┬──────────────┘
                                               │
                                               ▼
                                    ┌─────────────────────────┐
                                    │ 结果聚合消费者           │
                                    │ - Redis 缓存            │
                                    │ - WebSocket 推送        │
                                    │ - 告警触发              │
                                    └─────────────────────────┘
```

### 关键技术点

1. **消息队列解耦**: 使用 Kafka 实现检测服务和评估服务的解耦，提高系统稳定性
2. **流式任务生成**: Flink/Python 实时消费检测结果，生成评估任务
3. **多Key池化调度**: 
   - 支持 10+ 个 API Key 并发调用
   - 负载均衡策略 (轮询/最少负载)
   - 失败自动切换和冷却机制
4. **异步并发**: 使用 asyncio + aiohttp 实现高并发 API 调用
5. **可观测性**: Prometheus + Grafana 实时监控关键指标

---

## 📊 预期性能提升

| 指标 | 当前 (旧版) | 优化后 (目标) | 提升幅度 |
|-----|------------|--------------|---------|
| **并发摄像头数** | 1-5 路 | 50+ 路 | **10倍+** |
| **端到端延迟 (P95)** | 3-5 秒 | < 2 秒 | **40-60%** |
| **LLM 吞吐量** | 5-10 QPS | 50-100 QPS | **10倍** |
| **系统可用性** | 单点故障影响大 | 高可用、容错 | **显著提升** |
| **扩展性** | 垂直扩展受限 | 水平扩展 | **无限扩展** |

---

## 🔑 核心模块说明

### 1️⃣ Kafka 集成模块

**功能**: 
- 检测结果发布到 `detection-results` Topic
- 评估任务发布到 `assessment-tasks` Topic
- 评估结果发布到 `risk-assessment-results` Topic

**文件位置**: 
- `algo/kafka/detection_producer.py` (Producer 实现)
- `algo/kafka/base_consumer.py` (Consumer 基类)

**配置文件**: `config/kafka.yaml`

### 2️⃣ 任务生成器模块

**功能**:
- 消费 Kafka 检测结果
- 为每个群组生成评估任务
- 发送任务到调度器

**实现方案**:
- **方案 A**: Python 简化版 (`algo/task_generator/simple_generator.py`)
- **方案 B**: Flink 版本 (`flink_jobs/assessment_task_generator.py`)

### 3️⃣ API Key 池化调度器

**功能**:
- 管理 10+ 个 API Key
- 负载均衡调度 (最少负载策略)
- 失败自动重试和切换
- 自适应冷却机制

**文件位置**:
- `algo/scheduler/api_key_pool.py` (Key 池管理)
- `algo/scheduler/task_scheduler.py` (任务调度)

**配置文件**: `config/api_keys.yaml`

### 4️⃣ 结果聚合消费者

**功能**:
- 消费评估结果
- 与原始检测结果关联
- 缓存到 Redis
- 推送给 WebSocket 客户端
- 触发告警

**文件位置**: `algo/consumers/result_aggregator.py`

### 5️⃣ 监控模块

**功能**:
- 导出 Prometheus 指标
- Grafana 可视化
- 告警规则管理

**文件位置**: `algo/monitoring/metrics.py`

**配置文件**: `config/monitoring.yaml`

---

## 🚀 快速开始

### 第一步: 启动基础设施

```bash
cd /workspaces/Traffic-monitoring-web
docker-compose -f deployment/docker-compose.infra.yml up -d
```

### 第二步: 安装依赖

```bash
source .venv/bin/activate
pip install -r requirements-streaming.txt
```

### 第三步: 配置 API Keys

编辑 `config/api_keys.yaml`，添加你的 DashScope API Keys。

### 第四步: 初始化 Kafka Topics

```bash
python scripts/init_kafka_topics.py
```

### 第五步: 验证 API Keys

```bash
python scripts/verify_api_keys.py
```

### 第六步: 启动服务

```bash
# 终端 1: 检测服务
python app.py

# 终端 2: 任务生成器
python -m algo.task_generator.simple_generator

# 终端 3: LLM 调度器
python -m algo.scheduler.task_scheduler

# 终端 4: 结果消费者
python -m algo.consumers.result_aggregator
```

---

## 📝 下一步实施计划

### 阶段一: 核心模块开发 (Week 1-2)

- [ ] 实现 Kafka Producer 集成到 `DetectionPipeline`
- [ ] 开发 API Key 池管理模块
- [ ] 开发任务调度器 (异步并发调用)
- [ ] 开发 Python 任务生成器 (简化版)
- [ ] 实现结果聚合消费者

### 阶段二: 测试与优化 (Week 3)

- [ ] 单元测试 (各模块独立测试)
- [ ] 集成测试 (端到端流程)
- [ ] 性能测试 (单路->10路->50路)
- [ ] 压力测试 (模拟大量消息涌入)
- [ ] 故障恢复测试 (Key失效、Kafka宕机)

### 阶段三: 监控与文档 (Week 4)

- [ ] 配置 Prometheus 指标采集
- [ ] 搭建 Grafana 监控面板
- [ ] 配置告警规则
- [ ] 编写运维文档
- [ ] 编写故障排查手册

### 阶段四: 上线与优化 (Week 5-6)

- [ ] 灰度发布 (5路->20路->50路)
- [ ] 性能调优 (参数调整)
- [ ] 全量上线
- [ ] 持续监控和优化

---

## ✅ 验收标准

### 功能验收

- ✅ 所有模块成功部署并启动
- ✅ 检测结果正确发送到 Kafka
- ✅ 任务调度器使用所有配置的 API Key
- ✅ 评估结果正确发送并被消费

### 性能验收

- ✅ 支持 **50+路摄像头** 并发处理
- ✅ 端到端延迟 **< 2秒** (P95)
- ✅ API 调用成功率 **> 99%**
- ✅ 吞吐量提升 **10倍以上**
- ✅ Kafka 消息堆积 **< 1000条**

### 稳定性验收

- ✅ 单个 API Key 失效，系统自动切换
- ✅ Kafka 单节点宕机，系统继续运行
- ✅ 调度器重启，未处理任务不丢失
- ✅ 压测 2 小时无内存泄漏
- ✅ 7x24 小时稳定运行

---

## 🔧 技术栈总结

| 类别 | 技术 | 用途 |
|------|------|------|
| **消息队列** | Kafka | 解耦、异步处理、削峰填谷 |
| **流处理** | Flink / Python | 实时任务生成、数据转换 |
| **缓存** | Redis | 结果缓存、消息队列 |
| **监控** | Prometheus + Grafana | 指标采集、可视化 |
| **AI模型** | YOLO + Qwen-VL | 目标检测 + 风险评估 |
| **异步编程** | asyncio + aiohttp | 高并发 API 调用 |
| **配置管理** | YAML + Pydantic | 配置文件解析和验证 |

---

## 📚 相关资源

### 官方文档

- [Kafka 官方文档](https://kafka.apache.org/documentation/)
- [Flink 官方文档](https://nightlies.apache.org/flink/flink-docs-master/)
- [Prometheus 官方文档](https://prometheus.io/docs/)
- [DashScope API 文档](https://help.aliyun.com/zh/dashscope/)

### 项目文档

- [架构优化实施方案](./架构优化实施方案.md)
- [快速开始指南](./快速开始指南.md)
- [原项目 README](../README.md)

---

## 🆘 问题反馈

遇到问题或有建议？请通过以下方式联系：

- **GitHub Issues**: [提交 Issue](https://github.com/xyksghr-max/Traffic-monitoring-web/issues)
- **查看日志**: `tail -f logs/app.log`
- **检查监控**: http://localhost:3000 (Grafana)

---

## 🎉 总结

通过本次优化，系统将具备以下能力：

✅ **高并发**: 支持 50+ 路摄像头同时处理  
✅ **低延迟**: 端到端延迟 < 2 秒  
✅ **高可用**: 单点故障不影响整体  
✅ **可扩展**: 水平扩展能力  
✅ **可观测**: 完善的监控和告警  

**预祝项目实施顺利！🚀**
