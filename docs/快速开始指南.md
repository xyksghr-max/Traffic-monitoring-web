# 并发优化系统快速开始指南

## 📋 前提条件

### 环境要求
- Python 3.10+
- Docker & Docker Compose
- 至少 16GB 内存
- 多个 DashScope API Key (建议 5-10 个)

### 已安装服务
- Kafka 集群 (或使用 Docker Compose)
- Redis (用于结果缓存)
- Prometheus & Grafana (可选，用于监控)

---

## 🚀 快速启动步骤

### Step 1: 启动基础设施

使用 Docker Compose 一键启动 Kafka、Redis 等服务：

```bash
cd /workspaces/Traffic-monitoring-web
docker-compose -f deployment/docker-compose.infra.yml up -d
```

等待服务启动完成：
```bash
# 检查服务状态
docker-compose -f deployment/docker-compose.infra.yml ps
```

### Step 2: 安装 Python 依赖

```bash
# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装新增依赖
pip install -r requirements-streaming.txt
```

`requirements-streaming.txt` 包含:
```txt
confluent-kafka>=2.3.0
apache-flink>=1.18.0
aiohttp>=3.9.0
redis>=5.0.0
prometheus-client>=0.19.0
```

### Step 3: 配置 API Keys

编辑 `config/api_keys.yaml`:

```yaml
api_keys:
  - key: "sk-your-key-1"
    qps_limit: 10
    rpm_limit: 300
    enabled: true
  
  - key: "sk-your-key-2"
    qps_limit: 10
    rpm_limit: 300
    enabled: true
  
  - key: "sk-your-key-3"
    qps_limit: 10
    rpm_limit: 300
    enabled: true

scheduler:
  max_concurrent_tasks: 50
  key_cooldown_seconds: 60
  retry_max_attempts: 2
  timeout_seconds: 35
```

### Step 4: 配置 Kafka 连接

编辑 `config/kafka.yaml`:

```yaml
kafka:
  bootstrap_servers: "localhost:9092"
  
  topics:
    detection_results: "detection-results"
    assessment_tasks: "assessment-tasks"
    risk_assessment_results: "risk-assessment-results"
  
  producer:
    compression_type: "snappy"
    acks: 1
    linger_ms: 10
    batch_size: 32768
  
  consumer:
    group_id_prefix: "traffic-monitor"
    auto_offset_reset: "latest"
    enable_auto_commit: true
    auto_commit_interval_ms: 5000
```

### Step 5: 初始化 Kafka Topics

```bash
python scripts/init_kafka_topics.py
```

该脚本会创建必要的 Kafka Topics：
- `detection-results` (16 分区)
- `assessment-tasks` (16 分区)
- `risk-assessment-results` (16 分区)

### Step 6: 启动服务组件

**终端 1: 启动检测服务 (原有服务 + Kafka Producer)**
```bash
python app.py
```

**终端 2: 启动任务生成器 (可选 Flink 或 Python)**
```bash
# 方案 A: 使用 Python 简化版
python -m algo.task_generator.simple_generator

# 方案 B: 使用 Flink (需先安装 Flink)
flink run -py flink_jobs/assessment_task_generator.py
```

**终端 3: 启动 LLM 调度器**
```bash
python -m algo.scheduler.task_scheduler
```

**终端 4: 启动结果聚合消费者**
```bash
python -m algo.consumers.result_aggregator
```

### Step 7: 验证系统运行

#### 7.1 检查 Kafka 消息流

```bash
# 查看检测结果 topic
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic detection-results --from-beginning --max-messages 1

# 查看评估任务 topic
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic assessment-tasks --from-beginning --max-messages 1

# 查看风险评估结果 topic
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic risk-assessment-results --from-beginning --max-messages 1
```

#### 7.2 检查 API Key 池状态

访问监控端点：
```bash
curl http://localhost:5000/api/scheduler/stats
```

预期响应：
```json
{
  "code": 200,
  "data": {
    "total_keys": 3,
    "available_keys": 3,
    "in_use_keys": 0,
    "cooling_keys": 0,
    "total_calls": 145,
    "success_rate": 0.986,
    "keys": [
      {
        "key_id": "key_1",
        "status": "available",
        "total_calls": 48,
        "success_rate": 0.979
      },
      ...
    ]
  }
}
```

#### 7.3 测试端到端流程

运行测试脚本：
```bash
python scripts/test_streaming_pipeline.py --camera-id 1 --duration 60
```

该脚本会：
1. 启动一个测试摄像头
2. 监控消息流转
3. 验证端到端延迟
4. 输出性能报告

---

## 📊 监控面板

### Prometheus 指标

访问 `http://localhost:9090`，查询以下指标：

- **检测总数**: `detection_total`
- **LLM 调用总数**: `llm_calls_total{status="success"}`
- **LLM 延迟分布**: `llm_latency_seconds`
- **Kafka 消息堆积**: `kafka_consumer_lag`
- **API Key 状态**: `api_key_status`

### Grafana 仪表盘

访问 `http://localhost:3000` (默认账号: admin/admin)

导入预配置仪表盘：
```bash
# 导入 Grafana 配置
curl -X POST http://admin:admin@localhost:3000/api/dashboards/db \
  -H "Content-Type: application/json" \
  -d @deployment/grafana-dashboard.json
```

---

## 🧪 压力测试

### 单路摄像头测试

```bash
python scripts/benchmark.py \
  --cameras 1 \
  --duration 300 \
  --report-file reports/single_camera.json
```

### 多路并发测试

```bash
python scripts/benchmark.py \
  --cameras 50 \
  --duration 600 \
  --report-file reports/50_cameras.json
```

### 性能指标收集

测试报告会包含：
- 平均端到端延迟
- P50/P95/P99 延迟分布
- 吞吐量 (帧/秒)
- API 调用成功率
- Kafka 消息堆积情况

---

## 🔧 故障排查

### 问题 1: Kafka 连接失败

**症状**: 日志显示 `Failed to connect to Kafka`

**解决方案**:
```bash
# 检查 Kafka 服务状态
docker ps | grep kafka

# 检查网络连通性
telnet localhost 9092

# 重启 Kafka
docker-compose -f deployment/docker-compose.infra.yml restart kafka
```

### 问题 2: API Key 全部进入冷却状态

**症状**: 日志显示 `Failed to acquire API key within timeout`

**解决方案**:
1. 检查 API Key 是否有效:
   ```bash
   python scripts/verify_api_keys.py
   ```

2. 调整冷却时间 (在 `config/api_keys.yaml`):
   ```yaml
   scheduler:
     key_cooldown_seconds: 30  # 从 60 减少到 30
   ```

3. 增加更多 API Key

### 问题 3: 消息堆积严重

**症状**: Kafka lag 持续增长

**解决方案**:
1. 增加调度器并发数:
   ```yaml
   scheduler:
     max_concurrent_tasks: 100  # 从 50 提升到 100
   ```

2. 启动多个调度器实例:
   ```bash
   # 终端 1
   python -m algo.scheduler.task_scheduler --instance-id scheduler-1
   
   # 终端 2
   python -m algo.scheduler.task_scheduler --instance-id scheduler-2
   ```

3. 增加 Kafka 分区数:
   ```bash
   kafka-topics --bootstrap-server localhost:9092 \
     --alter --topic assessment-tasks --partitions 32
   ```

### 问题 4: 内存占用过高

**症状**: 系统内存持续增长

**解决方案**:
1. 限制消息缓存大小 (在 `config/kafka.yaml`):
   ```yaml
   consumer:
     max_poll_records: 100  # 限制每次拉取的消息数
   ```

2. 调整 Python GC:
   ```python
   import gc
   gc.set_threshold(700, 10, 5)  # 更频繁的垃圾回收
   ```

3. 使用对象池减少内存分配

---

## 📈 性能调优建议

### 1. Kafka 优化

**生产者配置**:
```yaml
producer:
  compression_type: "snappy"  # 压缩减少网络传输
  linger_ms: 10               # 批处理延迟
  batch_size: 65536           # 增大批处理大小 (从 32KB 到 64KB)
  buffer_memory: 67108864     # 64MB 缓冲区
  acks: 1                     # 平衡性能和可靠性
```

**消费者配置**:
```yaml
consumer:
  fetch_min_bytes: 1024       # 最小拉取大小
  fetch_max_wait_ms: 500      # 最大等待时间
  max_poll_records: 500       # 每次拉取记录数
```

### 2. API Key 池优化

**增加 Key 数量**:
- 理想比例: 1 个 Key 支持 5-10 路摄像头
- 50 路摄像头建议 10-15 个 Key

**调整冷却策略**:
```yaml
scheduler:
  key_cooldown_seconds: 30    # 缩短冷却时间
  adaptive_cooldown: true     # 启用自适应冷却
  min_cooldown: 10
  max_cooldown: 120
```

### 3. 并发控制

**调度器并发**:
```yaml
scheduler:
  max_concurrent_tasks: 100   # 根据硬件调整
  task_timeout_seconds: 40    # 任务超时
  queue_size: 500             # 任务队列大小
```

### 4. 监控告警阈值

在 `config/monitoring.yaml` 中设置:
```yaml
alerts:
  latency_threshold_p95: 2.5  # P95 延迟超过 2.5 秒告警
  error_rate_threshold: 0.05  # 错误率超过 5% 告警
  kafka_lag_threshold: 1000   # 消息堆积超过 1000 告警
  api_key_failure_threshold: 0.2  # 单 Key 失败率超过 20% 告警
```

---

## 🔄 升级与回滚

### 升级到新版本

```bash
# 1. 备份配置
cp -r config config.backup

# 2. 拉取最新代码
git pull origin main

# 3. 更新依赖
pip install -r requirements-streaming.txt --upgrade

# 4. 数据库迁移 (如有)
python scripts/migrate_schema.py

# 5. 滚动重启服务
# 先重启调度器 (零停机)
systemctl restart llm-scheduler-1
sleep 30
systemctl restart llm-scheduler-2

# 再重启检测服务
systemctl restart detection-pipeline
```

### 紧急回滚到旧版本

```bash
# 1. 停止所有新服务
docker-compose -f deployment/docker-compose.streaming.yml down

# 2. 恢复旧版本代码
git checkout <previous-commit-hash>

# 3. 恢复配置
cp -r config.backup config

# 4. 重启旧版服务
python app.py
```

---

## 📚 相关文档

- [架构优化实施方案](./架构优化实施方案.md) - 详细技术方案
- [API 文档](./API文档.md) - 接口定义
- [运维手册](./运维手册.md) - 部署和维护指南
- [故障排查手册](./故障排查手册.md) - 常见问题解决

---

## 🆘 获取帮助

遇到问题？尝试以下方式：

1. **查看日志**:
   ```bash
   # 应用日志
   tail -f logs/app.log
   
   # 调度器日志
   tail -f logs/scheduler.log
   
   # Kafka 日志
   docker logs -f kafka
   ```

2. **检查健康状态**:
   ```bash
   curl http://localhost:5000/api/health/health_check
   curl http://localhost:5000/api/scheduler/health
   ```

3. **提交 Issue**: [GitHub Issues](https://github.com/xyksghr-max/Traffic-monitoring-web/issues)

4. **查看监控面板**: http://localhost:3000

---

**祝部署顺利！🎉**
